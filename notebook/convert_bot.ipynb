{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import Not\n",
    "from calendar import c\n",
    "import json\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\admin\\\\Enhance\\\\debug_hc\\\\json\\data\\\\\"\n",
    "\n",
    "BOT_NAME = input(\"Enter json file name to convert, without .json: \")\n",
    "\n",
    "with open(file_path + BOT_NAME + \".json\", \"r\", encoding='utf-8') as fi:\n",
    "    data = json.load(fi)\n",
    "\n",
    "data = data[\"nlp\"]\n",
    "parsed = dict()\n",
    "\n",
    "parsed[\"api_key\"] = \"\"\n",
    "parsed[\"app_code\"] = BOT_NAME\n",
    "parsed[\"callback\"] = {\"error\":\"\", \"success\":\"\"}\n",
    "parsed[\"dictionary\"] = [{\"alternatives\":[], \"phrase\":\"\"}]\n",
    "parsed[\"domain\"] = \"\"\n",
    "parsed[\"engine\"] = \"nlu\"\n",
    "parsed[\"language\"] = \"vi\"\n",
    "parsed[\"no_accent\"] = False\n",
    "parsed[\"sub_language\"] = \"\"\n",
    "\n",
    "entities = []\n",
    "for each in data[\"entities\"]:\n",
    "    entity = each[\"label\"]\n",
    "\n",
    "    type_ = \"keyword & freetext\"\n",
    "    if each[\"type\"] == 0:\n",
    "        entities.append({\n",
    "            \"entity\": entity,\n",
    "            \"type\": \"builtin\",\n",
    "            \"values\": []\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    elif each[\"type\"] == 1:\n",
    "        type_ = \"keyword & freetext\"\n",
    "\n",
    "    elif each[\"type\"] == 2:\n",
    "        type_ = \"keyword\"\n",
    "\n",
    "    elif each[\"type\"] == 3:\n",
    "        type_ = \"freetext\"\n",
    "    \n",
    "    values = []\n",
    "    for kw in data[\"keywords\"]:\n",
    "        if kw[\"entity\"] == entity:\n",
    "            xpress = [each.strip('\\\"') for each in kw[\"synonym\"].strip('][').split(',')]\n",
    "            if len(xpress) == 1 and xpress[0] == \"\":\n",
    "                xpress = []\n",
    "            values.append({\n",
    "                \"expressions\": xpress,\n",
    "                \"value\": kw[\"value\"]\n",
    "            })\n",
    "\n",
    "    entities.append({\n",
    "            \"entity\": entity,\n",
    "            \"type\": type_,\n",
    "            \"values\": values\n",
    "        })\n",
    "\n",
    "parsed[\"entities\"] = entities\n",
    "\n",
    "samples = []\n",
    "for each in data[\"samples\"]:\n",
    "    ntties = []\n",
    "    for ntt in each[\"entities\"]:\n",
    "        subntties = []\n",
    "        for sub in ntt[\"sub_entities\"]:\n",
    "            subntties.append({\n",
    "                \"end\": sub[\"end\"],\n",
    "                \"entity\": sub[\"label\"],\n",
    "                \"start\": sub[\"start\"],\n",
    "                \"value\": sub[\"value\"]\n",
    "            })\n",
    "\n",
    "        ntties.append({\n",
    "            \"end\": ntt[\"end\"],\n",
    "            \"entity\": ntt[\"label\"],\n",
    "            \"start\": ntt[\"start\"],\n",
    "            \"subentities\": subntties,\n",
    "            \"value\": ntt[\"value\"]\n",
    "        })\n",
    "\n",
    "    samples.append({\n",
    "        \"text\": each[\"content\"],\n",
    "        \"intent\": each[\"intent\"],\n",
    "        \"entities\": ntties\n",
    "    })\n",
    "\n",
    "parsed[\"samples\"] = samples\n",
    "\n",
    "with open(file_path + BOT_NAME + \"_output.json\", \"w\", encoding='utf-8') as fo:\n",
    "    json.dump(parsed, fo, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
